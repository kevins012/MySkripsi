{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "391eda6f-2119-4c5a-884d-f48a8be9ea85",
   "metadata": {},
   "source": [
    "WITH VIDIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb11262e-09c9-451b-92e5-57e6cb415840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 22, 42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"model/model_dinamis1.h5\")\n",
    "\n",
    "# Cek input shape model\n",
    "model.input_shape  # (None, 35, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83442892-2724-4e0e-8802-fe492db55ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi(data, d2max, d2min=0):\n",
    "    dmin, dmax = np.min(data), np.max(data)\n",
    "    return ((data - dmin) / (dmax - dmin)) * (d2max - d2min) + d2min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "203408f0-0574-4a86-b5d6-230aa5309182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi2(data):\n",
    "    vektor = [(d-data[0])*100  for d in data[1:] ]\n",
    "    return vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e674537-2ffb-4c04-9865-e82bbdb3f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_points(points, new_x_max):\n",
    "    \"\"\"\n",
    "    Melakukan transformasi skala pada kumpulan titik berdasarkan nilai maksimum baru untuk sumbu X.\n",
    "    \n",
    "    Parameters:\n",
    "        points (numpy.ndarray): Array 2D berisi koordinat titik, dengan kolom pertama sebagai X dan kedua sebagai Y.\n",
    "        new_x_max (float): Nilai maksimum baru untuk sumbu X setelah transformasi.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Array 2D dari titik yang telah ditransformasi.\n",
    "    \"\"\"\n",
    "    # Nilai maksimum awal untuk X\n",
    "    x_max_original = np.max(points[:, 0])\n",
    "    \n",
    "    # Hitung skala\n",
    "    scale = new_x_max / x_max_original\n",
    "    \n",
    "    # Transformasi titik berdasarkan skala\n",
    "    transformed_points = (points * scale)\n",
    "    \n",
    "    return transformed_points[:,0],transformed_points[:,1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c85700f-f999-483f-98e8-0398f0c19ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105,\n",
       " 101,\n",
       " 109,\n",
       " 110,\n",
       " 112,\n",
       " 113,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 120,\n",
       " 104,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 111,\n",
       " 116,\n",
       " 117]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = [\n",
    "    100, 101, 102, 103, 104, 105, 106,\n",
    "    107, 108, 109, 110, 111, 112,\n",
    "    113, 114, 115, 116, 117, 118, 119, 120\n",
    "]\n",
    "\n",
    "indices = [5, 1, 9, 10, 12, 13, 15, 16, 17, 20, 4, 6, 7, 8, 11, 16, 17]\n",
    "\n",
    "selected =[arr[i] for i in indices]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53320b15-7098-45ee-871e-f8636c47d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum:\n",
      "[[8 2 1 1 4 1 3]\n",
      " [2 4 8 1 8 3 5]\n",
      " [1 4 9 7 4 5 3]\n",
      " [6 7 1 9 7 9 4]]\n",
      "\n",
      "Setelah:\n",
      "[[8 2 1 0 0 0 0]\n",
      " [2 4 8 1 8 3 5]\n",
      " [1 4 9 7 4 5 3]\n",
      " [6 7 1 9 7 9 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Buat array acak 4x7\n",
    "arr = np.random.randint(1, 10, size=(4, 7))\n",
    "print(\"Sebelum:\")\n",
    "print(arr)\n",
    "\n",
    "# Ubah kolom ke-5 dan ke-6 (alias -2:) pada baris ke-0 jadi 0\n",
    "arr[0, -4:] = 0\n",
    "\n",
    "print(\"\\nSetelah:\")\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84c16fc-95ab-471c-aeaa-93c7f488b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi2(data):\n",
    "    vektor = [(d-data[0] )for d in data[1:] ]\n",
    "    return vektor\n",
    "def scale_points(points, new_x_max):\n",
    "    \"\"\"\n",
    "    Melakukan transformasi skala pada kumpulan titik berdasarkan nilai maksimum baru untuk sumbu X.\n",
    "    \n",
    "    Parameters:\n",
    "        points (numpy.ndarray): Array 2D berisi koordinat titik, dengan kolom pertama sebagai X dan kedua sebagai Y.\n",
    "        new_x_max (float): Nilai maksimum baru untuk sumbu X setelah transformasi.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Array 2D dari titik yang telah ditransformasi.\n",
    "    \"\"\"\n",
    "    # Nilai maksimum awal untuk X\n",
    "    x_max_original = np.max(points[:, 0])\n",
    "    \n",
    "    # Hitung skala\n",
    "    scale = new_x_max / x_max_original\n",
    "    \n",
    "    # Transformasi titik berdasarkan skala\n",
    "    transformed_points = (points * scale)\n",
    "    \n",
    "    return transformed_points[:,0],transformed_points[:,1]\n",
    "    \n",
    "    \n",
    "def normalisasi(data):\n",
    "    dmin, dmax = np.min(data), np.max(data)\n",
    "    return (data - dmin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78c83458-afbb-49a1-a08d-7738a3ea463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trim_sequence(seq, target_len=20):\n",
    "    if len(seq) <= target_len:\n",
    "        return list(seq)\n",
    "\n",
    "    total = len(seq)\n",
    "    frame_interval = total / target_len\n",
    "\n",
    "    trimmed = []\n",
    "    for i in range(target_len):\n",
    "        idx = int(np.ceil(i * frame_interval))\n",
    "        if idx >= total:\n",
    "            idx = total - 1\n",
    "        trimmed.append(seq[idx])\n",
    "\n",
    "    return trimmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0978eba0-4e66-4c0d-9380-512e774b7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_sequence(seq, target_len=22):\n",
    "    if len(seq) <= target_len:\n",
    "        return list(seq)\n",
    "\n",
    "    keep_first = seq[0]\n",
    "    keep_last = seq[-1]\n",
    "    middle = list(seq)[1:-1]\n",
    "\n",
    "    total_to_keep = target_len - 2\n",
    "    step = len(middle) / total_to_keep\n",
    "\n",
    "    trimmed_middle = [middle[int(i * step)] for i in range(total_to_keep)]\n",
    "\n",
    "    return [keep_first] + trimmed_middle + [keep_last]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846c8b94-ecee-4e4c-9f04-739a5a4c7142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([5,1,9,10,12,13,15,16,17,20,4,6,7,8,11,16,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13351649-07ca-420d-9e5b-028041dd1abe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m.input_shape \n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.input_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6584df1-90d3-4eda-9d03-8f1c9cc197e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1,9,10,12,13,16,17,20,4,6,8,11,16])+len([2,3,4,7,9,10,11,12,15,19,20,16,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b1f17c-890e-4705-a49b-4bd9de53a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model/static/label_model_2.pkl', 'rb') as f:\n",
    "    label_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4861d193-f13a-49e2-ae59-4fc8efdd7167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_X)+len(cols_Y)\n",
    "len(cols_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1993a30-3cb6-4c73-a7ac-f2e082a7db73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '10',\n",
       " 1: 'cepat',\n",
       " 2: 'j',\n",
       " 3: 'kita',\n",
       " 4: 'lihat',\n",
       " 5: 'menang',\n",
       " 6: 'paham',\n",
       " 7: 'tidak',\n",
       " 8: 'z'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c09e281-7227-4bff-ac85-47da0d403660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6785865a-113d-457a-b921-ffb2791b1cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 22, 30)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"model/model_dinamis2.h5\")\n",
    "model.input_shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3de95fd9-31b3-4a7e-93e2-a6bcd6809326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 7])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=np.array([1,4,5,7,8,22,34,123,10,54])\n",
    "s[[4,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a22b660-018d-44a0-aaf1-f9953b1e8417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "I0000 00:00:1746020986.002604  129946 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1746020986.004482  131892 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) Graphics (RPL-S)\n",
      "W0000 00:00:1746020986.027105  131894 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746020986.050577  131903 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tidak (0.62)\n",
      "tidak (0.85)\n",
      "tidak (0.63)\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "\n",
    "# ==================== SETUP ====================\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"model/model_dinamis3.h5\")\n",
    "\n",
    "# Cek input shape model\n",
    "input_shape = model.input_shape  # (None, 35, 21)\n",
    "frame_count = input_shape[1]     # 35\n",
    "feature_per_frame = input_shape[2]  # 21\n",
    "\n",
    "# Mapping label\n",
    "\n",
    "# cols_X = [5,1,9,10,12,13,15,16,17,20,4,6,7,8,11,16,17]\n",
    "# cols_Y = [2,3,4,7,9,10,11,12,15,19,20,16,17]\n",
    "cols_X = sorted([1,9,10,12,13,16,17,20,4,6,8,11,16])\n",
    "cols_Y = sorted([2,3,4,7,9,10,11,12,15,19,20,16,17])\n",
    "\n",
    "cols_Z= [4,7,11,15]\n",
    "# MediaPipe setup\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_hands=1,\n",
    "    running_mode=vision.RunningMode.IMAGE\n",
    ")\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# Inisialisasi deque untuk menyimpan fitur dari frame sebelumnya\n",
    "sequence = deque(maxlen=47)\n",
    "a=0\n",
    "# Buka video\n",
    "cap = cv2.VideoCapture('video2/kita/5.mp4')\n",
    "if not cap.isOpened():\n",
    "    print(\"Gagal membuka video.\")\n",
    "    exit()\n",
    "k=False\n",
    "# ==================== LOOP VIDEO FRAME ====================\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocessing untuk MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "    result = detector.detect(mp_image)\n",
    "\n",
    "    label_text = \"Menunggu 35 frame...\"\n",
    "\n",
    "    if result.hand_landmarks:\n",
    "        a+=1\n",
    "        for hand in result.hand_landmarks:\n",
    "            \n",
    "            features = []\n",
    "            x_coor = []\n",
    "            y_coor = []\n",
    "            z_coor = []\n",
    "            \n",
    "                  # Hanya nilai x\n",
    "                \n",
    "            nilai_X = np.array([landmark.x for landmark in hand])\n",
    "            nilai_Y = np.array([landmark.y for landmark in hand])\n",
    "            # nilai_Z = np.array([landmark.z for landmark in hand])\n",
    "            try :\n",
    "                vektorX = (nilai_X[cols_X] - X_before)\n",
    "                vektorY = (nilai_Y[cols_Y]-Y_before)\n",
    "                \n",
    "            except:\n",
    "                vektorX = [0] * len(cols_X)\n",
    "                vektorY =[0] * len(cols_Y)\n",
    " \n",
    "            # X_before =nilai_X[[4,5,8,12,13,18,20]]\n",
    "            # Y_before=nilai_Y[[2,4,5,8,12,13,18,20]]\n",
    "            X_before =nilai_X[cols_X]\n",
    "            Y_before=nilai_Y[cols_Y]\n",
    "            # newX = normalisasi(nilai_X,(np.max(nilai_X)-np.min(nilai_X))) \n",
    "            # newY = normalisasi(nilai_Y,(np.max(nilai_Y)-np.min(nilai_Y)))\n",
    "            # newX = normalisasi(nilai_X,10) \n",
    "            # newY = normalisasi(nilai_Y,10)\n",
    "            # newX = normalisasi(nilai_X,(np.max(nilai_X)-np.min(nilai_X))) \n",
    "            # newY = normalisasi(nilai_Y,(np.max(nilai_Y)-np.min(nilai_Y)))\n",
    "            # newXY = np.column_stack((newX, newY) )  # Simpan dalam list koordinat int\n",
    "            \n",
    "            # newX , newY = scale_points(newXY,10)\n",
    "\n",
    "            # features = np.concatenate([np.array(newX)[[i-1 for i in cols_X]], np.array(newY)[[i-1 for i in cols_Y]], np.array(z_coor), np.array(vektorX), np.array(vektorY)])\n",
    "# ,nilai_Z[cols_Z]\n",
    "            features = np.concatenate( [vektorX, vektorY])\n",
    "\n",
    "            \n",
    "            \n",
    "           \n",
    "            if len(features) == feature_per_frame:\n",
    "                sequence.append(features)\n",
    "\n",
    "        \n",
    "    # if len(sequence) == 20:\n",
    "    #     sequence[0] [-4:] = 0\n",
    "    #     input_data = np.array(sequence).reshape(1, frame_count, feature_per_frame)\n",
    "    #     prediction = model.predict(input_data, verbose=0)\n",
    "    #     predicted_class = np.argmax(prediction)\n",
    "    #     confidence = np.max(prediction)\n",
    "    #     if confidence >0.9:\n",
    "    #         label_text = f\"{label_map[predicted_class]} ({confidence:.2f})\"\n",
    "    #         print(label_text)\n",
    "    \n",
    "    if len(sequence) == 47:\n",
    "        trimmed = trim_sequence(sequence, target_len=22)\n",
    "        # trimmed[0][-15:] = 0 \n",
    "        \n",
    "        trimmed[0][:] = 0  # manipulasi frame pertama jika diperlukan\n",
    "      \n",
    "    \n",
    "        input_data = np.array(trimmed).reshape(1, 22, feature_per_frame)\n",
    "   \n",
    "        prediction = model.predict(input_data, verbose=0)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        confidence = np.max(prediction)\n",
    "\n",
    "        if confidence > 0.7:\n",
    "            label_text = f\"{label_map[predicted_class]} ({confidence:.2f})\"\n",
    "      \n",
    "        print(f\"{label_map[predicted_class]} ({confidence:.2f})\")\n",
    "\n",
    "    # else:\n",
    "        \n",
    "    #     print(len(sequence))\n",
    "    # ==================== TAMPILKAN HASIL ====================\n",
    "    cv2.putText(frame, label_text, (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Prediksi Gesture\", frame)\n",
    "\n",
    "    # Tekan 'q' untuk keluar\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "print(a)\n",
    "# ==================== SELESAI ====================\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7709c91b-b101-43f8-a76a-618bc8624ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5.55267302e+00,  4.00553383e+00,  2.97857649e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 5.45309890e+00,  4.14128657e+00,  2.76753588e+00, ...,\n",
       "         -5.68091869e-04, -4.14782763e-03, -4.70882654e-03],\n",
       "        [ 5.56296307e+00,  4.06510881e+00,  2.89787088e+00, ...,\n",
       "          2.65777111e-04,  1.25557184e-03,  1.71250105e-03],\n",
       "        ...,\n",
       "        [ 4.69980414e+00,  4.69144266e+00,  1.02620271e+00, ...,\n",
       "         -6.03571534e-03,  5.89740276e-03,  5.16951084e-03],\n",
       "        [ 5.20940748e+00,  4.97202066e+00,  1.46059476e+00, ...,\n",
       "         -8.81057978e-03,  6.27863407e-03,  7.77918100e-03],\n",
       "        [ 2.75593061e+00,  6.07231492e+00, -3.01098025e+00, ...,\n",
       "         -1.84898674e-02, -3.96609306e-04, -1.68466568e-03]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ec0f3b-6424-4028-a166-1a8ca7f34c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi2(data):\n",
    "    vektor = [(d-data[0] )for d in data[1:] ]\n",
    "    return vektor\n",
    "def scale_points(points, new_x_max):\n",
    "    \"\"\"\n",
    "    Melakukan transformasi skala pada kumpulan titik berdasarkan nilai maksimum baru untuk sumbu X.\n",
    "    \n",
    "    Parameters:\n",
    "        points (numpy.ndarray): Array 2D berisi koordinat titik, dengan kolom pertama sebagai X dan kedua sebagai Y.\n",
    "        new_x_max (float): Nilai maksimum baru untuk sumbu X setelah transformasi.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Array 2D dari titik yang telah ditransformasi.\n",
    "    \"\"\"\n",
    "    # Nilai maksimum awal untuk X\n",
    "    x_max_original = np.max(points[:, 0])\n",
    "    \n",
    "    # Hitung skala\n",
    "    scale = new_x_max / x_max_original\n",
    "    \n",
    "    # Transformasi titik berdasarkan skala\n",
    "    transformed_points = (points * scale)\n",
    "    \n",
    "    return transformed_points[:,0],transformed_points[:,1]\n",
    "    \n",
    "    \n",
    "def trim_sequence(seq, target_len=20):\n",
    "    if len(seq) <= target_len:\n",
    "        return list(seq)\n",
    "\n",
    "    keep_first = seq[0]\n",
    "    keep_last = seq[-1]\n",
    "    middle = list(seq)[1:-1]\n",
    "\n",
    "    total_to_keep = target_len - 2\n",
    "    step = len(middle) / total_to_keep\n",
    "\n",
    "    trimmed_middle = [middle[int(i * step)] for i in range(total_to_keep)]\n",
    "\n",
    "    return [keep_first] + trimmed_middle + [keep_last]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c844405-308d-45e2-b7e1-8ba05c2681b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 21:55:09.764053: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-28 21:55:09.764829: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-28 21:55:09.768763: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-28 21:55:09.780004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745852109.798664  176183 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745852109.804217  176183 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745852109.818557  176183 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745852109.818575  176183 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745852109.818578  176183 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745852109.818579  176183 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 21:55:09.823433: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1745852113.843910  176183 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1745852113.844364  176183 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745852114.067893  176183 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1745852114.071924  176539 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) Graphics (RPL-S)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1745852114.119456  176546 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745852114.162325  176554 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745852114.710184  176567 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16623105  0.10319284  0.11400534  0.14951983  0.19511817  0.05387402\n",
      "  0.0970255   0.1156432  -0.01335321 -0.02155675  0.29947548  0.20399563\n",
      "  0.22937201  0.25159724  0.17424926  0.1156432  -0.01335321 -0.09149259\n",
      " -0.17222619 -0.23541251 -0.44553868 -0.28236705 -0.41094124 -0.49304187\n",
      " -0.56280035 -0.482959   -0.40945755 -0.4734613  -0.55879262 -0.24465623\n",
      "  0.58328128  0.          0.          0.          0.        ]\n",
      "[ 0.15918644  0.09462734  0.10781354  0.15066703  0.20617612  0.04702491\n",
      "  0.09883451  0.11885379 -0.01973344 -0.02569389  0.29678707  0.20275326\n",
      "  0.23298059  0.25925376  0.18061031  0.11885379 -0.01973344 -0.07835329\n",
      " -0.15363055 -0.21859553 -0.42731056 -0.27008498 -0.39210653 -0.47282168\n",
      " -0.54135478 -0.47780123 -0.40192997 -0.46289012 -0.55308434 -0.24359152\n",
      "  0.58608603  0.          0.          0.          0.        ]\n",
      "[ 0.16440426  0.0968812   0.11358002  0.16020404  0.21714737  0.05084747\n",
      "  0.11120731  0.13307367 -0.01783711 -0.01084322  0.29816304  0.21176292\n",
      "  0.24250914  0.26857881  0.19227861  0.13307367 -0.01783711 -0.06865805\n",
      " -0.14091188 -0.20820871 -0.41714525 -0.25298193 -0.38329698 -0.47087681\n",
      " -0.54682222 -0.46443507 -0.39405231 -0.46208666 -0.54589358 -0.22493526\n",
      "  0.58682203  0.          0.          0.          0.        ]\n",
      "[ 0.1797452   0.10142481  0.13023105  0.18579963  0.25460643  0.06930858\n",
      "  0.13868976  0.164496    0.0013991   0.03680395  0.31225866  0.23251671\n",
      "  0.26760322  0.29759085  0.22345456  0.164496    0.0013991  -0.049447\n",
      " -0.12251025 -0.18551725 -0.3891774  -0.22921386 -0.36149177 -0.44552022\n",
      " -0.52002469 -0.43671784 -0.37015192 -0.43523858 -0.51740757 -0.20646325\n",
      "  0.58061856  0.          0.          0.          0.        ]\n",
      "[ 0.1797452   0.10142481  0.13023105  0.18579963  0.25460643  0.06930858\n",
      "  0.13868976  0.164496    0.0013991   0.03680395  0.31225866  0.23251671\n",
      "  0.26760322  0.29759085  0.22345456  0.164496    0.0013991  -0.049447\n",
      " -0.12251025 -0.18551725 -0.3891774  -0.22921386 -0.36149177 -0.44552022\n",
      " -0.52002469 -0.43671784 -0.37015192 -0.43523858 -0.51740757 -0.20646325\n",
      "  0.58061856  0.          0.          0.          0.        ]\n",
      "[ 0.18115546  0.10243551  0.13367431  0.18940087  0.25793938  0.07537094\n",
      "  0.14435567  0.16889234  0.00941236  0.07161072  0.31250133  0.23724084\n",
      "  0.27194504  0.29943214  0.22813655  0.16889234  0.00941236 -0.04766995\n",
      " -0.11801288 -0.1810666  -0.38035221 -0.23684865 -0.36512782 -0.44727752\n",
      " -0.52057865 -0.44093116 -0.33021837 -0.37915361 -0.51962951 -0.2137486\n",
      "  0.58537805  0.          0.          0.          0.        ]\n",
      "[ 0.18775585  0.10138115  0.14169866  0.20235395  0.27746406  0.08446267\n",
      "  0.16372803  0.19613269  0.0196896   0.1068058   0.31797314  0.24425006\n",
      "  0.28127116  0.31078354  0.2446892   0.19613269  0.0196896  -0.03508013\n",
      " -0.0997842  -0.15344131 -0.35802726 -0.22722563 -0.34821917 -0.42847048\n",
      " -0.50146949 -0.42509711 -0.30734113 -0.33288127 -0.49486735 -0.21267888\n",
      "  0.58492798  0.          0.          0.          0.        ]\n",
      "[ 0.18975978  0.1011724   0.14431606  0.20551325  0.28437318  0.08801775\n",
      "  0.17153291  0.20419671  0.02479596  0.10988809  0.31571735  0.24874948\n",
      "  0.28997453  0.32266696  0.24982251  0.20419671  0.02479596 -0.02296674\n",
      " -0.08738741 -0.13851997 -0.34280694 -0.22493517 -0.34019609 -0.4187763\n",
      " -0.48786646 -0.41617575 -0.28025889 -0.295912   -0.48074231 -0.2177318\n",
      "  0.58241022  0.          0.          0.          0.        ]\n",
      "[ 0.18975978  0.1011724   0.14431606  0.20551325  0.28437318  0.08801775\n",
      "  0.17153291  0.20419671  0.02479596  0.10988809  0.31571735  0.24874948\n",
      "  0.28997453  0.32266696  0.24982251  0.20419671  0.02479596 -0.02296674\n",
      " -0.08738741 -0.13851997 -0.34280694 -0.22493517 -0.34019609 -0.4187763\n",
      " -0.48786646 -0.41617575 -0.28025889 -0.295912   -0.48074231 -0.2177318\n",
      "  0.58241022  0.          0.          0.          0.        ]\n",
      "[ 0.18975978  0.1011724   0.14431606  0.20551325  0.28437318  0.08801775\n",
      "  0.17153291  0.20419671  0.02479596  0.10988809  0.31571735  0.24874948\n",
      "  0.28997453  0.32266696  0.24982251  0.20419671  0.02479596 -0.02296674\n",
      " -0.08738741 -0.13851997 -0.34280694 -0.22493517 -0.34019609 -0.4187763\n",
      " -0.48786646 -0.41617575 -0.28025889 -0.295912   -0.48074231 -0.2177318\n",
      "  0.58241022  0.          0.          0.          0.        ]\n",
      "[ 0.18975978  0.1011724   0.14431606  0.20551325  0.28437318  0.08801775\n",
      "  0.17153291  0.20419671  0.02479596  0.10988809  0.31571735  0.24874948\n",
      "  0.28997453  0.32266696  0.24982251  0.20419671  0.02479596 -0.02296674\n",
      " -0.08738741 -0.13851997 -0.34280694 -0.22493517 -0.34019609 -0.4187763\n",
      " -0.48786646 -0.41617575 -0.28025889 -0.295912   -0.48074231 -0.2177318\n",
      "  0.58241022  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# ==================== SETUP ====================\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"model/model_dinamis1.h5\")\n",
    "\n",
    "# Cek input shape model\n",
    "input_shape = model.input_shape  # (None, 35, 21)\n",
    "frame_count = input_shape[1]     # 35\n",
    "feature_per_frame = input_shape[2]  # 21\n",
    "\n",
    "# Mapping label\n",
    "label_map = {\n",
    "    0: '10',\n",
    "    1: 'j',\n",
    "    2: 'kita',\n",
    "    3: 'lihat',\n",
    "    4: 'menang',\n",
    "    5: 'paham',\n",
    "    6: 'percaya',\n",
    "    7: 'tidak',\n",
    "    8: 'z'\n",
    "}\n",
    "\n",
    "cols_X = [5,1,9,10,12,13,15,16,17,20,4,6,7,8,11,16,17]\n",
    "cols_Y = [2,3,4,7,9,10,11,12,15,19,20,16,17]\n",
    "\n",
    "# MediaPipe setup\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_hands=1,\n",
    "    running_mode=vision.RunningMode.IMAGE\n",
    ")\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# Queue untuk antar thread\n",
    "frame_queue = queue.Queue(maxsize=1)\n",
    "result_queue = queue.Queue(maxsize=1)\n",
    "\n",
    "# Sequence buffer\n",
    "sequence = deque(maxlen=34)\n",
    "\n",
    "# Untuk simpan posisi sebelumnya\n",
    "X_before = None\n",
    "Y_before = None\n",
    "a=0\n",
    "# ==================== Worker Thread ====================\n",
    "def worker_thread():\n",
    "    global X_before, Y_before\n",
    "    while True:\n",
    "        frame = frame_queue.get()\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "        result = detector.detect(mp_image)\n",
    "\n",
    "        label_text = \"Menunggu 35 frame...\"\n",
    "\n",
    "        if result.hand_landmarks:\n",
    "            a+=1\n",
    "            \n",
    "            for hand in result.hand_landmarks:\n",
    "                features = []\n",
    "                z_coor = []\n",
    "\n",
    "                for idx, landmark in enumerate(hand):\n",
    "                    if idx in [0]:\n",
    "                        z_coor.append(landmark.y)\n",
    "                        break\n",
    "\n",
    "                nilai_X = np.array([landmark.x for landmark in hand])\n",
    "                nilai_Y = np.array([landmark.y for landmark in hand])\n",
    "\n",
    "                try:\n",
    "                    vektorX = (nilai_X[[5,13]] - X_before)*100\n",
    "                    vektorY =( nilai_Y[[5,13]] - Y_before)*100\n",
    "                except:\n",
    "                    vektorX = [0,0]\n",
    "                    vektorY = [0,0]\n",
    "\n",
    "                X_before = nilai_X[[5,13]]\n",
    "                Y_before = nilai_Y[[5,13]]\n",
    "\n",
    "                # Normalisasi dan scaling\n",
    "                newX = normalisasi2(nilai_X)\n",
    "                newY = normalisasi2(nilai_Y)\n",
    "\n",
    "                features = np.concatenate([\n",
    "                    np.array(newX)[[i-1 for i in cols_X]],\n",
    "                    np.array(newY)[[i-1 for i in cols_Y]],\n",
    "                    np.array(z_coor),\n",
    "                    np.array(vektorX),\n",
    "                    np.array(vektorY)\n",
    "                ])\n",
    "\n",
    "                if len(features) == feature_per_frame:\n",
    "                    sequence.append(features)\n",
    "\n",
    "        if len(sequence) == 34:\n",
    "            trimmed = trim_sequence(sequence, target_len=20)\n",
    "            trimmed[0][-4:] = 0\n",
    "\n",
    "            input_data = np.array(trimmed).reshape(1, 20, feature_per_frame)\n",
    "            \n",
    "            prediction = model.predict(input_data, verbose=0)\n",
    "            predicted_class = np.argmax(prediction)\n",
    "            confidence = np.max(prediction)\n",
    "\n",
    "            # if confidence > 0.8:\n",
    "            label_text = f\"{label_map[predicted_class]} ({confidence:.2f})\"\n",
    "            # else:\n",
    "            #     label_text = \"Confidence rendah\"\n",
    "\n",
    "        result_queue.put(label_text)\n",
    "\n",
    "# ==================== Jalankan Thread ====================\n",
    "thread = threading.Thread(target=worker_thread)\n",
    "thread.start()\n",
    "\n",
    "# ==================== Buka Kamera ====================\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Gagal membuka kamera.\")\n",
    "    exit()\n",
    "\n",
    "# ==================== Main Loop ====================\n",
    "label_text = \"Menunggu prediksi...\"\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Kirim frame ke worker kalau kosong\n",
    "    if frame_queue.empty():\n",
    "        frame_queue.put(frame.copy())\n",
    "\n",
    "    # Ambil hasil prediksi\n",
    "    if not result_queue.empty():\n",
    "        label_text = result_queue.get()\n",
    "\n",
    "    # Tampilkan hasil\n",
    "    cv2.putText(frame, label_text, (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Prediksi Gesture\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ==================== Cleanup ====================\n",
    "frame_queue.put(None)\n",
    "thread.join()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf9db0-a89f-4dd2-8c45-0ffbf482e3a6",
   "metadata": {},
   "source": [
    "# A=[4,6,7]-1\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "216f995e-2b1e-4ce8-8d54-6c1dc85325c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.344488058993418,\n",
       " 4.862725916083305,\n",
       " 3.0361821286676602,\n",
       " 3.6643433792403552,\n",
       " 5.679546334193772,\n",
       " 0.9634049214684152,\n",
       " 2.983103087117691,\n",
       " 3.731197574922718,\n",
       " -0.5073061141976531,\n",
       " 2.021927993327787,\n",
       " 10.0,\n",
       " 5.67088860918689,\n",
       " 6.708728632511193,\n",
       " 7.6076310899946264,\n",
       " 4.829184533224432,\n",
       " 3.731197574922718,\n",
       " -0.5073061141976531]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[newX[i-1] for i in cols_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d816d70-aed3-49d5-a0be-d13b491c8485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b312b6-76a8-465c-9494-cbcf791259b8",
   "metadata": {},
   "source": [
    "REALTIME IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dfbc0cd-fd85-4711-98c2-e7661cd56aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 20:22:09.496387: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-27 20:22:09.497105: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-27 20:22:09.500736: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-27 20:22:09.511041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745760129.528264   13558 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745760129.533448   13558 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745760129.546122   13558 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745760129.546140   13558 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745760129.546142   13558 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745760129.546143   13558 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-27 20:22:09.550544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1745760131.846061   13558 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1745760131.846449   13558 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745760132.064925   13558 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1745760132.070780   13902 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) Graphics (RPL-S)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1745760132.111925   13904 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745760132.137517   13924 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745760132.669874   13910 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "\n",
    "# ==================== SETUP ====================\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"model/model_2.h5\")\n",
    "\n",
    "# Ambil input shape model (misalnya: (None, 35, 21))\n",
    "input_shape = model.input_shape\n",
    "frame_count = input_shape[1]         # 35\n",
    "feature_per_frame = input_shape[2]   # 21\n",
    "\n",
    "# Mapping label (pastikan ini sesuai urutan training)\n",
    "label_map = {0: 'paham', 1: 'percaya',2: 'tidak', 3: 'kita'}\n",
    "\n",
    "# Setup MediaPipe\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_hands=1,\n",
    "    running_mode=vision.RunningMode.IMAGE\n",
    ")\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# Inisialisasi buffer untuk menyimpan frame\n",
    "sequence = deque(maxlen=frame_count)\n",
    "\n",
    "# Buka webcam (real-time)\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Tidak dapat membuka webcam.\")\n",
    "    exit()\n",
    "\n",
    "# ==================== LOOP FRAME REAL-TIME ====================\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Ubah ke RGB untuk MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "    result = detector.detect(mp_image)\n",
    "\n",
    "    label_text = \"Menunggu 35 frame...\"\n",
    "\n",
    "    # Ambil fitur dari hand landmarks jika ada\n",
    "    if result.hand_landmarks:\n",
    "        for hand in result.hand_landmarks:\n",
    "            features = []\n",
    "            x_coor = []\n",
    "            y_coor = []\n",
    "            for idx, landmark in enumerate(hand):\n",
    "                # features.append(landmark.x) \n",
    "                if idx in [0,1,3,4,5,7,9,11,12,14,15,17,19,21]:\n",
    "                    x_coor.append(landmark.x)\n",
    "                if idx in [0,1,3,4,11,12]:\n",
    "                    y_coor.append(landmark.y)\n",
    "                  # Hanya nilai x\n",
    "            features = x_coor +y_coor\n",
    "            if len(features) == feature_per_frame:\n",
    "                sequence.append(features)\n",
    "    # Jika sudah cukup 35 frame, prediksi gesture\n",
    "    if len(sequence) == frame_count:\n",
    "        input_data = np.array(sequence).reshape(1, frame_count, feature_per_frame)\n",
    "        prediction = model.predict(input_data, verbose=0)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        confidence = np.max(prediction)\n",
    "        label_text = f\"{label_map[predicted_class]} ({confidence:.2f})\"\n",
    "       \n",
    "\n",
    "    # Tampilkan hasil prediksi di layar\n",
    "    cv2.putText(frame, label_text, (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "\n",
    "    # Tampilkan frame di jendela\n",
    "    cv2.imshow(\"Real-time Gesture Prediction\", frame)\n",
    "\n",
    "    # Tekan 'q' untuk keluar\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ==================== SELESAI ====================\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c7d7e5-920d-46b0-be47-ab21a1fd1025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 88, 63, 3, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indek = [1,4,3]\n",
    "\n",
    "iw = [0,6,7,63,88]\n",
    "[iw[i] for i in indek]+[3,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0a792f-26a3-40db-818c-4952fcaf294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi(data, d2max, d2min=0):\n",
    "    dmin, dmax = np.min(data), np.max(data)\n",
    "    return ((data - dmin) / (dmax - dmin)) * (d2max - d2min) + d2min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c5452b-5795-4e8a-9c81-0549e7781838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9743949f-b153-44ba-ae97-917016f52501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_numbersY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e47c30-28e5-4647-9d3a-3d9aa7fd9513",
   "metadata": {},
   "source": [
    "IMPLEMENTASI DATA STATIS WITH NORMALISASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a62fffb-10cd-4f71-b387-0367396a07e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "I0000 00:00:1744650791.912720   41744 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1744650791.915042   76594 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) Graphics (RPL-S)\n",
      "W0000 00:00:1744650791.933671   76595 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744650791.946965   76598 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "\n",
    "# ==================== SETUP ====================\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"model/model_static_filter.h5\")\n",
    "\n",
    "label_map={\n",
    "  0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g',\n",
    "  7: 'h', 8: 'i', 9: 'k', 10: 'l', 11: 'm', 12: 'n',\n",
    "  13: 'o', 14: 'p', 15: 'q', 16: 'r', 17: 's',\n",
    "  18: 't', 19: 'u', 20: 'v', 21: 'w', 22: 'x', 23: 'y'\n",
    "}\n",
    "column_numbers = [0, 1, 12,5,16,9,10,7,20,15]  # Ganti dengan indeks kolom yang diinginkan\n",
    "column_numbersY = [4,20,14,19,3,15,2,11,9,3,4,11,10,12]\n",
    "\n",
    "# MediaPipe setup\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_hands=1,\n",
    "    running_mode=vision.RunningMode.IMAGE\n",
    ")\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# Inisialisasi deque untuk menyimpan fitur dari frame sebelumnya\n",
    "\n",
    "\n",
    "# Buka video\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Gagal membuka video.\")\n",
    "    exit()\n",
    "# ==================== LOOP VIDEO FRAME ====================\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocessing untuk MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "    result = detector.detect(mp_image)\n",
    "\n",
    "    label_text = \"Menunggu 35 frame...\"\n",
    "\n",
    "    if result.hand_landmarks:\n",
    "        for hand in result.hand_landmarks:\n",
    "            landmark_points = []  # Menyimpan titik untuk koneksi garis\n",
    "\n",
    "            # Ekstrak semua titik koordinat\n",
    "            nilai_X = np.array([landmark.x for landmark in hand])\n",
    "            nilai_Y = np.array([landmark.y for landmark in hand])\n",
    "\n",
    "            newX = normalisasi(nilai_X, (np.max(nilai_X) - np.min(nilai_X)))\n",
    "            newY = normalisasi(nilai_Y, (np.max(nilai_Y) - np.min(nilai_Y)))\n",
    "       \n",
    "\n",
    "            newXY = [newX[i] for i in column_numbers]+[newY[i] for i in column_numbersY] # Simpan dalam list koordinat int\n",
    "\n",
    "                #z_coords.append(landmark.z)\n",
    "    \n",
    "            # Buat dictionary untuk DataFrame dengan format X1, X2,..., Y1, Y2,..., Z\n",
    "            # row_data = {f\"X{idx}\": x for idx, x in zip(range(0,21),newX)}\n",
    "            # row_data.update({f\"Y{idx}\": y for idx, y in zip(range(0,21),newY)})\n",
    "            # row_data.update({f\"Z{idx}\": y for idx, y in zip(range(0,21),newY)})\n",
    "                  # Hanya nilai x\n",
    "          \n",
    "         \n",
    "            k=np.array([newXY])\n",
    "     \n",
    "\n",
    "            prediction = model.predict(k, verbose=0)\n",
    "            predicted_class = np.argmax(prediction)\n",
    "            confidence = np.max(prediction)\n",
    "            label_text = f\"{label_map[predicted_class]} ({confidence:.2f})\"\n",
    "\n",
    "      \n",
    "\n",
    "    # ==================== TAMPILKAN HASIL ====================\n",
    "    cv2.putText(frame, label_text, (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Prediksi Gesture\", frame)\n",
    "\n",
    "    # Tekan 'q' untuk keluar\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "       \n",
    "\n",
    "# ==================== SELESAI ====================\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee999b6-10c1-4299-82d5-7b4eb585fe19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ecc61-f8aa-4cc5-8e69-e36dc7938c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
